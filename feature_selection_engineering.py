# -*- coding: utf-8 -*-
"""Feature Selection / Engineering

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ajSrThWU98Tka8Nxa_2ENd8ufrMKlyck
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import metrics
import seaborn as sns
sns.set()

# Load Data from Project folder
Data = pd.read_excel("/content/Data_Train.xlsx")

# To stretch head function output to the notebook width
pd.set_option('display.max_columns', None)

Data.head()

Data.info()       # Print Data Types

Data.isnull().sum()

# Remove rows with missing values
Data.dropna(inplace = True)

Data.isnull().sum()

Data.head()

# Date_of_Journey is the day when plane departs.
Data["day_of_journey"] = pd.to_datetime(Data.Date_of_Journey, format="%d/%m/%Y").dt.day
Data["month_of_journey"] = pd.to_datetime(Data["Date_of_Journey"], format = "%d/%m/%Y").dt.month
Data.head()

# Since we have converted Date_of_Journey column into integers, Now we can drop as it is of no use.
Data.drop(["Date_of_Journey"], axis = 1, inplace = True)

# Departure time is when a plane leaves the gate.
# Similar to Date_of_Journey we can extract values from Dep_Time
# Extracting Hours
Data["depature_hour"] = pd.to_datetime(Data["Dep_Time"]).dt.hour
# Extracting Minutes
Data["depature_min"] = pd.to_datetime(Data["Dep_Time"]).dt.minute
# Now we drop Dep_Time as it is of no use
Data.drop(["Dep_Time"], axis = 1, inplace = True)

# Arrival time is when the plane pulls up to the gate.
# Similar to Date_of_Journey we can extract values from Arrival_Time

# Extracting Hours
Data["arrival_hour"] = pd.to_datetime(Data["Arrival_Time"]).dt.hour
# Extracting Minutes
Data["arrival_min"] = pd.to_datetime(Data["Arrival_Time"]).dt.minute
# Now we can drop Arrival_Time as it is of no use
Data.drop(["Arrival_Time"], axis = 1, inplace = True)

Data.head()

# Duration is the time taken by plane to reach destination
# It is the difference betwen Arrival Time and Departure time
# Assigning and converting Duration column into list, for looping through
duration = list(Data["Duration"])
# In table above, Row Index=2, we have Duration = 19h (missing minutes)
# Looping through all duration values, to ensure it has both hours & mins: 'xh ym'
for i in range(len(duration)):
    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins
        if "h" in duration[i]:
            duration[i] = duration[i].strip() + " 0m"   # Adds 0 minute
        else:
            duration[i] = "0h " + duration[i]           # Adds 0 hour
# Prepare separate duration_hours and duration_mins lists
duration_hours = []
duration_mins = []
for i in range(len(duration)):
    duration_hours.append(int(duration[i].split(sep = "h")[0]))    # Extract hours from duration
    duration_mins.append(int(duration[i].split(sep = "m")[0].split()[-1]))   # Extracts only minutes from duration

# Add duration_hours and duration_mins list to our Data df
Data["Duration_hours"] = duration_hours
Data["Duration_mins"] = duration_mins
# Drop Duration column from the Data
Data.drop(["Duration"], axis = 1, inplace = True)

Data.head()

"""### Feature Selection


1. <span style="color: blue;">**Correlation**</span> ▶ Features must be correlated with the target. If a feature does not exhibit a correlation, it is a prime target for elimination.

"""

# correlation between target and features
(Data.corr().loc['Price']
 .plot(kind='barh', figsize=(4,10)))

"""### Feature Selection
2. <span style="color: blue;">**Low variance features**</span> ▶
Dropping low variance features is often necessary in machine learning for ***Reducing Overfitting*** and are more likely to be correlated with other features, leading to ***multicollinearity***.
"""

import numpy as np
# variance of numeric features
(Data
 .select_dtypes(include=np.number)
 .var()
 .astype('str'))

"""Here **Total_Stops** and **month_of_journey** has an extremely low variance, so this is an ideal candidate for elimination. However, in these  cases, I’d be reluctant to drop it since there values range between 0 and 4 for Total_Stops and values range between 3 and 6 for Total_Stops, therefore a low variance is expected:"""

Data['Total_Stops'].describe(

)

Data['month_of_journey'].describe()

"""### Feature Selection
3. <span style="color: blue;">**Multicollinearity**</span> ▶
Multicollinearity arises when there is a correlation between any two features. In machine learning, it is expected that each feature should be independent of others, i.e., there’s no colinearity between them. Multicollinearity can cause issues in the model, such as unstable coefficient estimates and difficulty in interpreting feature contributions.
"""

import matplotlib.pyplot as plt
sns.set(rc={'figure.figsize':(16,10)})
sns.heatmap(Data.corr(),
            annot=True,
            linewidths=.5,
            center=0,
            cbar=False,
            cmap="PiYG")
plt.show()

a = Data[['Source', 'Destination']]
a.sample(5)

b = pd.crosstab(a['Source'], a['Destination'])
b

"""Similar to numeric features, you can also check collinearity between categorical variables. Statistical tests such as the Chi-squared test of independence is ideal for it.

The outputs are, in order of appearance, the Chi-squared value, the p-value, the degree of freedom and an array of expected frequencies.

"""

from scipy.stats import chi2_contingency
chi2_contingency(b)

# Feature engineering on: Airline
Data["Airline"].value_counts()

# As Airline is Nominal Categorical data we will perform OneHotEncoding
Airline = Data[["Airline"]]
Airline_List = Airline['Airline']
New_Airline = []

for carrier in Airline_List:
  if carrier in ['Jet Airways', 'IndiGo', 'Air India', 'SpiceJet',
       'Multiple carriers', 'GoAir', 'Vistara', 'Air Asia']:
    New_Airline.append(carrier)
  else:
    New_Airline.append('Other')

Airline['Airline'] = pd.DataFrame(New_Airline)
Airline['Airline'].value_counts()

Airline = pd.get_dummies(Airline, drop_first= True)
Airline.head()

# Feature engineering on: Source
Data["Source"].value_counts()

# As Source is Nominal Categorical data we will perform OneHotEncoding
Source = Data[["Source"]]
Source = pd.get_dummies(Source, drop_first= True)
# drop_first= True means we drop the first column to prevent multicollinearity
Source.head()

# Feature engineering on: Destination
Data["Destination"].value_counts()

# Renaming destination 'New Delhi' to 'Delhi' - to match with Source
Destination = Data[["Destination"]]
Current_Destination_List = Destination['Destination']
New_Destination_List = []

for value in Current_Destination_List:
  if value in ['New Delhi']:
    New_Destination_List.append('Delhi')
  else:
    New_Destination_List.append(value)

Destination['Destination'] = pd.DataFrame(New_Destination_List)

# As Destination is Nominal Categorical data we will perform OneHotEncoding
Destination = pd.get_dummies(Destination, drop_first = True)
Destination.head()

# Additional_Info contains almost 80% no_info
# Route and Total_Stops are related to each other
Data.drop(["Route", "Additional_Info"], axis = 1, inplace = True)

# Feature engineering on: Total_Stops
Data["Total_Stops"].value_counts()

# As this is case of Ordinal Categorical type we perform LabelEncoder
# Here Values are assigned with corresponding keys
Data.replace({"non-stop": 0, "1 stop": 1, "2 stops": 2, "3 stops": 3, "4 stops": 4}, inplace = True)
Data.head()

# Concatenate dataframe --> train_data + Airline + Source + Destination
data_train = pd.concat([Data, Airline, Source, Destination], axis = 1) # axis = 1 signifies column
data_train.drop(["Airline", "Source", "Destination"], axis = 1, inplace = True)

data_train.head()

data_train.shape

data_train.columns

X = data_train.loc[:, ['Total_Stops', 'day_of_journey', 'month_of_journey', 'depature_hour',
       'depature_min', 'arrival_hour', 'arrival_min', 'Duration_hours',
       'Duration_mins', 'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',
       'Airline_Jet Airways', 'Airline_Multiple carriers', 'Airline_Other',
       'Airline_SpiceJet', 'Airline_Vistara', 'Source_Chennai', 'Source_Delhi',
       'Source_Kolkata', 'Source_Mumbai', 'Destination_Cochin',
       'Destination_Delhi', 'Destination_Hyderabad', 'Destination_Kolkata']]
y = data_train.iloc[:, 1]

print(X.shape, y.shape)

"""### Feature Selection
4. <span style="color: blue;">**p-value**</span> ▶
p-value tells us whether the relationship between a predictor and the target is statistically significant.


"""

import statsmodels.api as sm
ols = sm.OLS(y, X).fit()
print(ols.summary())

"""### Feature Selection
5. <span style="color: blue;">**Feature importance**</span> ▶
The feature importance values obtained from individual decision trees in the ensemble are averaged or summed to obtain the final feature importance scores.


"""

# Important feature using ExtraTreesRegressor
from sklearn.ensemble import ExtraTreesRegressor
selection = ExtraTreesRegressor()
selection.fit(X, y)

print(selection.feature_importances_)

#plot graph of feature importances for better visualization
plt.figure(figsize = (12,8))
feat_importances = pd.Series(selection.feature_importances_, index=X.columns)
feat_importances.nlargest(25).plot(kind='barh')
plt.show()

"""### Feature Selection
6. <span style="color: blue;">**Variance Inflation Factor (VIF)**</span> ▶
Variance Inflation Factor (VIF) is another way to measure multicollinearity. A high VIF of a feature indicates that it is correlated with one or more other features.

"""

from statsmodels.stats.outliers_influence import variance_inflation_factor
def Calculate_VIF(z):
    # Calculating Variable Inflation Factor (VIF)
    vif = pd.DataFrame()
    vif["variables"] = z.columns
    vif["VIF"] = [variance_inflation_factor(z.values, i) for i in range(z.shape[1])]
    return(vif)

# Compute VIF on X
Calculate_VIF(X)

# Drop 'Source_Delhi'
X = data_train.loc[:, ['Total_Stops', 'day_of_journey', 'month_of_journey', 'depature_hour',
       'depature_min', 'arrival_hour', 'arrival_min', 'Duration_hours',
       'Duration_mins', 'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',
       'Airline_Jet Airways', 'Airline_Multiple carriers', 'Airline_Other',
       'Airline_SpiceJet', 'Airline_Vistara', 'Source_Chennai',
       'Source_Kolkata', 'Source_Mumbai', 'Destination_Cochin',
       'Destination_Delhi', 'Destination_Hyderabad', 'Destination_Kolkata']]
X.head()

